{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por Refuerzo: el Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo en el blog [Aprende Machine Learning](http://www.aprendemachinelearning.com) en Español.\n",
    "\n",
    "Crearemos el juego del pong con interface gráfica de Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Agente deberá aprender a jugar sólo mediante premios y castigos.\n",
    "\n",
    "Crearemos las clases:\n",
    "\n",
    "* Agente: implementará el algoritmo de QLearning\n",
    "* Environment: será nuestro tablero de juego\n",
    "\n",
    "Y crearemos una función para comenzar a jugar, donde entrenará iterando miles de partidas de pong.\n",
    "\n",
    "Finalmente, ejecutarmos 1 partida con el agente ya entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:21:01.578976Z",
     "start_time": "2020-12-27T10:20:58.063893Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:24.177788Z",
     "start_time": "2020-12-27T10:22:24.158177Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:39.529477Z",
     "start_time": "2020-12-27T10:22:39.493343Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:51.265359Z",
     "start_time": "2020-12-27T10:22:51.249319Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
    "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:24:06.516334Z",
     "start_time": "2020-12-27T10:22:51.808220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 16 ]  AVG Steps[ 224 ] Max Score[ 130 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 27 ]  AVG Steps[ 260 ] Max Score[ 180 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 29 ]  AVG Steps[ 269 ] Max Score[ 190 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 30 ]  AVG Steps[ 271 ] Max Score[ 350 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 32 ]  AVG Steps[ 280 ] Max Score[ 370 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 34 ]  AVG Steps[ 287 ] Max Score[ 370 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 37 ]  AVG Steps[ 297 ] Max Score[ 480 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 40 ]  AVG Steps[ 306 ] Max Score[ 480 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 40 ]  AVG Steps[ 306 ] Max Score[ 480 ]\n",
      "Partidas[ 4999 ] Avg.Puntos[ 40 ] Max score[ 480 ] en partida[ 3425 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:35:16.554658Z",
     "start_time": "2020-12-27T10:25:44.533659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
